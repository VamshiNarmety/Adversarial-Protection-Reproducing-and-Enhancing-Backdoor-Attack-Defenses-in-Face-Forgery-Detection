# Adversarial-Protection-Reproducing-and-Enhancing-Backdoor-Attack-Defenses-in-Face-Forgery-Detection
  This project reproduces the backdoor attacks on models trained to detect face forgeries, examining how these attacks impact the model's ability to distinguish between real and fake faces.
  The project also explores defense mechanism to identify and neutralize these attacks without comprimising the model's performance
  here are the links to selected papers:
   i) [Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection](https://arxiv.org/abs/2402.11473v1)
   ii)[BadActs: A Universal Backdoor Defense in the Activation Space](https://arxiv.org/abs/2405.11227v1)
# Datasets
we use three datasets from kaggle:
1. **Fakeforensics++** and **celebDF(V2)**: These have both real and fake faces made with different deepfake techniques.
2. **Real-v/s-Fake**: This has real and fake faces made with styleGAN
